{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Datetime recognizer</h1>\n",
    "Train a model to recognize any datetimes in a given text string. \n",
    "\n",
    "Start with simple iso8601s and then progress to locales, timezones, countries & conventions.\n",
    "\n",
    "\n",
    "Starting from the Keras autoencoder example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/lib64'\n",
    "os.environ['CUDA_HOME'] = '/usr/local/cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning to decode localized datetimes from strings\n",
    "Input: \"Monday 31 December 2007 07:07:07.0000000 +02:00 CET/Europe\"\n",
    "or\n",
    "       \"Monday, 24 October 1977 at 09:10:55 Greenwich Mean Time\"\n",
    "Output: \"2007-12-31T07:07:07.00000+02:00\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "\n",
    "\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "\n",
    "'''\n",
    "from keras.models import Sequential\n",
    "from keras.engine.training import slice_X\n",
    "from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import pytz\n",
    "from datetime import datetime, timezone\n",
    "import itertools\n",
    "import random\n",
    "from babel import Locale, localedata, UnknownLocaleError\n",
    "from babel.dates import format_datetime\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    '''\n",
    "    Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    '''\n",
    "    def __init__(self, country_codes, maxlen):\n",
    "        self.chars = set(string.ascii_letters + \n",
    "                         string.punctuation + \n",
    "                         string.digits\n",
    "                        )\n",
    "\n",
    "        ts_from = int(datetime(1980, 1, 1, tzinfo=timezone.utc).timestamp())\n",
    "        ts_to   = int(datetime(1981, 1, 1, tzinfo=timezone.utc).timestamp())\n",
    "        tstamps = [t for t in range(ts_from, ts_to, 60*1000)]\n",
    "        retries = 0\n",
    "        \n",
    "        #Hoover up all the non-ascii characters that might be needed\n",
    "        for country_code in tqdm(country_codes):\n",
    "            try:                            \n",
    "                if pytz.country_timezones.get(country_code):\n",
    "                    for ctzone in pytz.country_timezones(country_code):\n",
    "                        tzone = pytz.timezone(ctzone)\n",
    "                        country_locale = Locale.parse('und_' + country_code)\n",
    "                        for fmt  in ['short',' medium','long','full']:\n",
    "                            ydts = [datetime.utcfromtimestamp(t).replace(tzinfo=tzone) for t in tstamps]\n",
    "                            if random.choice([True, False]):\n",
    "                                X = [format_datetime(dt, format=fmt, locale=country_locale) for dt in ydts]\n",
    "                            else:\n",
    "                                sep = random.choice([' ','T'])\n",
    "                                X = [dt.isoformat(sep) for dt in ydts]\n",
    "\n",
    "                            # So that's a years worth of datetimes for all the countrys & locales & timezones \n",
    "                            for ln in X:\n",
    "                                # Going with case sensitive because some dt formats have an \"i\"\n",
    "                                self.chars = self.chars.union( set(iter(ln)))\n",
    "                                \n",
    "            except UnknownLocaleError:                    \n",
    "                if retries >=21:\n",
    "                    raise # Somethings gone wrong!\n",
    "\n",
    "        self.chars = sorted(self.chars)\n",
    "\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def encode(self, C, maxlen=None):\n",
    "        maxlen = maxlen if maxlen else self.maxlen\n",
    "        X = np.zeros((maxlen, len(self.chars)))\n",
    "        for i, c in enumerate(C[:maxlen]):\n",
    "            X[i, self.char_indices[c]] = 1\n",
    "        return X\n",
    "\n",
    "    def decode(self, X, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            X = X.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ctable = CharacterTable(COUNTRY_CODES, MAXLEN_X)\n",
    "#ctable.chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DateTimeDataGenerator(sample_size):   \n",
    "    while True:        \n",
    "        # 0xFFFFFFFF 32 bit unsigned max 2106\n",
    "        # 0x7FFFFFFF 32 bit   signed max 2038\n",
    "        tstamps = [random.randrange(0xFFFFFFFF) for _ in range(sample_size)]\n",
    "\n",
    "        yield tstamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DateTimeIsoGenerator(country_codes, sample_size, maxlen_x, maxlen_y, invert):\n",
    "    \"\"\"Simplest case for training, straing 86012, no timezone.\n",
    "    \"\"\"\n",
    "    dtdg = DateTimeDataGenerator(sample_size)\n",
    "    \n",
    "    while True:        \n",
    "        # 0xFFFFFFFF 32 bit unsigned max 2106\n",
    "        # 0x7FFFFFFF 32 bit   signed max 2038\n",
    "        tstamps = next(dtdg)\n",
    "\n",
    "        ydts = [datetime.utcfromtimestamp(t).isoformat('T') for t in tstamps]\n",
    "        sep = random.choice([' ','T'])\n",
    "        X = [datetime.utcfromtimestamp(t).isoformat(sep) for t in tstamps] \n",
    "\n",
    "        # pad or chop to length\n",
    "        X    = [(pp + (' '*maxlen_x))[:maxlen_x] for pp in X]\n",
    "        ydts = [(pp + (' '*maxlen_y))[:maxlen_y] for pp in ydts]\n",
    "        \n",
    "        if invert:\n",
    "            X = [xx[::-1] for xx in X]\n",
    "            \n",
    "        yield (X, ydts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DateTimeFormattedGenerator(country_codes, sample_size, maxlen_x, maxlen_y, invert):\n",
    "    dtdg = DateTimeDataGenerator(sample_size)\n",
    "    all_locales = localedata.locale_identifiers()\n",
    "    \n",
    "    while True:        \n",
    "        # 0xFFFFFFFF 32 bit unsigned max 2106\n",
    "        # 0x7FFFFFFF 32 bit   signed max 2038\n",
    "        tstamps = next(dtdg)\n",
    "\n",
    "        # Pick a country and timezone\n",
    "        for retries in range(32):\n",
    "            try:\n",
    "                country_code = random.choice(country_codes)\n",
    "                timezone = pytz.timezone(random.choice(pytz.country_timezones(country_code)))\n",
    "                country_locale = Locale.parse('und_' + country_code)\n",
    "                break\n",
    "            except UnknownLocaleError:\n",
    "                print('UnknownLocaleError: %s'%'und_' + country_code, file=sys.stderr)\n",
    "                if retries >=31:\n",
    "                    raise # Somethings gone wrong!\n",
    "                    \n",
    "        ydts = [datetime.utcfromtimestamp(t).replace(tzinfo=timezone).isoformat('T') for t in tstamps]\n",
    "        \n",
    "\n",
    "        fmt = random.choice(['short',' medium','long','full'])\n",
    "        X = [format_datetime(datetime.utcfromtimestamp(t).replace(tzinfo=timezone), \n",
    "                             format=fmt, \n",
    "                             locale=country_locale\n",
    "                            ) for t in tstamps]\n",
    "\n",
    "        # pad or chop to length\n",
    "        X    = [(pp + (' '*maxlen_x))[:maxlen_x] for pp in X]\n",
    "        ydts = [(pp + (' '*maxlen_y))[:maxlen_y] for pp in ydts]\n",
    "        \n",
    "        if invert:\n",
    "            X = [xx[::-1] for xx in X]\n",
    "            \n",
    "        yield (X, ydts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DateTimeVectorGenerator(dt_generator, ctable):    \n",
    "    X_next, y_next = next(dt_generator)\n",
    "    while True:\n",
    "        # X_next are all the same MAXLEN_X length. Same for y_next\n",
    "        X = np.zeros((len(X_next), len(X_next[0]), len(ctable.chars)), dtype=np.bool)\n",
    "        y = np.zeros((len(y_next), len(y_next[0]), len(ctable.chars)), dtype=np.bool)\n",
    "        \n",
    "        for i, sentence in enumerate(X_next):\n",
    "            X[i] = ctable.encode(sentence, len(X_next[0]))\n",
    "            \n",
    "        for i, sentence in enumerate(y_next):\n",
    "            y[i] = ctable.encode(sentence, len(y_next[0]))\n",
    "        \n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_history(learning_hist, data_filename=None):    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    discard = int(math.ceil(len(learning_hist)/100))*5\n",
    "    # skip the first few, they destroy plot scale\n",
    "    plt.plot([i.history['loss']     for i in learning_hist][discard:], label='loss')\n",
    "    plt.plot([i.history['val_loss'] for i in learning_hist][discard:], label='val_loss')\n",
    "\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.legend()\n",
    "    #plt.ylim([0, 0.005])\n",
    "    plt.title('training error')\n",
    "    if (data_filename is not None):\n",
    "        plt.savefig(data_filename)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset\n",
    "TRAINING_SIZE   = 1111 #gn1 #50000\n",
    "VALIDATION_SIZE = 111\n",
    "INVERT = True\n",
    "# Try replacing GRU, or SimpleRNN\n",
    "RNN = recurrent.GRU\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "LAYERS = 1\n",
    "MAXLEN_X = 72 # longer than anything expected like 'Monday 31 December 2000 07:07:07.0000000 +02:00 CET/Europe'\n",
    "MAXLEN_Y = len(datetime.now().isoformat(' '))\n",
    "COUNTRY_CODES = ['GB', ] #'US','DE','FR','ES','IT','CA', 'NO','SE','DK','FI','EE','CZ','PL'] # pytz.country_names.keys()\n",
    "\n",
    "HIDDEN_SIZE = MAXLEN_X * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.12it/s]\n"
     ]
    }
   ],
   "source": [
    "ctable = CharacterTable(COUNTRY_CODES, MAXLEN_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1111, 72, 95)\n",
      "y_train.shape: (1111, 26, 95)\n"
     ]
    }
   ],
   "source": [
    "gen_dt = DateTimeIsoGenerator(COUNTRY_CODES, TRAINING_SIZE, MAXLEN_X, MAXLEN_Y, INVERT)\n",
    "#gen_dt = DateTimeFormattedGenerator(COUNTRY_CODES, TRAINING_SIZE, MAXLEN_X, MAXLEN_Y, INVERT)\n",
    "\n",
    "gen_vec_train      = DateTimeVectorGenerator(gen_dt, ctable)\n",
    "gen_vec_validation = DateTimeVectorGenerator(gen_dt, ctable)\n",
    "\n",
    "X_train, y_train = next(gen_vec_train)\n",
    "print('X_train.shape: %s'%str(X_train.shape))\n",
    "print('y_train.shape: %s'%str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "gru_7 (GRU)                      (None, 360)           492480      gru_input_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_4 (RepeatVector)    (None, 26, 360)       0           gru_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_8 (GRU)                      (None, 26, 360)       778680      repeatvector_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_4 (TimeDistribute(None, 26, 95)        34295       gru_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 26, 95)        0           timedistributed_4[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 1305455\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE\n",
    "# note: in a situation where your input sequences have a variable length,\n",
    "# use inputhttps://scherbatsky.local:8000/notebooks/ml/datetime%20autoencoder-Copy1.ipynb#_shape=(None, nb_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN_X, len(ctable.chars))))\n",
    "# For the decoder's input, we repeat the encoded input for each time step\n",
    "model.add(RepeatVector(MAXLEN_Y))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer\n",
    "for _ in range(LAYERS):\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# For each of step of the output sequence, decide which character should be chosen\n",
    "model.add(TimeDistributed(Dense(len(ctable.chars))))\n",
    "model.add(Activation('softmax'))\n",
    "opt = RMSprop(lr=0.01, decay=0.95)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_hist = []\n",
    "gen_dt_test = DateTimeIsoGenerator(COUNTRY_CODES, TRAINING_SIZE, MAXLEN_X, MAXLEN_Y, INVERT)\n",
    "#gen_dt_test = DateTimeFormattedGenerator(COUNTRY_CODES, TRAINING_SIZE, MAXLEN_X, MAXLEN_Y, INVERT)\n",
    "\n",
    "gen_vec_test = DateTimeVectorGenerator(gen_dt_test, ctable)\n",
    "\n",
    "X_test, y_test = next(gen_vec_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "69993/69993 [==============================] - 40s - loss: 2.1977 - acc: 0.3764 - val_loss: 1.6809 - val_acc: 0.5177\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "69993/69993 [==============================] - 37s - loss: 1.5851 - acc: 0.5306 - val_loss: 1.4802 - val_acc: 0.5863\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "69993/69993 [==============================] - 41s - loss: 1.3981 - acc: 0.5977 - val_loss: 1.3155 - val_acc: 0.6130\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "69993/69993 [==============================] - 41s - loss: 1.2495 - acc: 0.6098 - val_loss: 1.1863 - val_acc: 0.6150\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "69993/69993 [==============================] - 37s - loss: 1.1401 - acc: 0.6179 - val_loss: 1.1119 - val_acc: 0.6140\n",
      "Q 2082-12-26 01:57:13                                                     \n",
      "T 2082-12-26T01:57:13       \n",
      "\u001b[91m☒\u001b[0m 2091-01-11T1::::::        \n",
      "Q 2082-12-26 01:57:13                                                     \n",
      "T 2082-12-26T01:57:13       \n",
      "\u001b[91m☒\u001b[0m 2091-01-11T1::::::        \n",
      "Q 2082-12-26 01:57:13                                                     \n",
      "T 2082-12-26T01:57:13       \n",
      "\u001b[91m☒\u001b[0m 2091-01-11T1::::::        \n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "69993/69993 [==============================] - 43s - loss: 1.0628 - acc: 0.6304 - val_loss: 1.0353 - val_acc: 0.6310\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "69993/69993 [==============================] - 38s - loss: 1.0035 - acc: 0.6441 - val_loss: 0.9928 - val_acc: 0.6455\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "69993/69993 [==============================] - 41s - loss: 0.9659 - acc: 0.6501 - val_loss: 0.9406 - val_acc: 0.6618\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "69993/69993 [==============================] - 39s - loss: 0.9345 - acc: 0.6578 - val_loss: 0.9181 - val_acc: 0.6542\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/1\n",
      "69993/69993 [==============================] - 38s - loss: 0.9130 - acc: 0.6581 - val_loss: 0.9052 - val_acc: 0.6542\n",
      "Q 2082-12-26 01:57:13                                                     \n",
      "T 2082-12-26T01:57:13       \n",
      "\u001b[91m☒\u001b[0m 2092-02-21T12:21:25       \n",
      "Q 2082-12-26 01:57:13                                                     \n",
      "T 2082-12-26T01:57:13       \n",
      "\u001b[91m☒\u001b[0m 2092-02-21T12:21:25       \n",
      "Q 2082-12-26 01:57:13                                                     \n",
      "T 2082-12-26T01:57:13       \n",
      "\u001b[91m☒\u001b[0m 2092-02-21T12:21:25       \n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/1\n",
      "34441/69993 [=============>................] - ETA: 19s - loss: 0.8981 - acc: 0.6658"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation dataset\n",
    "\n",
    "for iteration in range(1, 40+1):\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    \n",
    "    # switch locale (probably)\n",
    "    gen_dt_train = DateTimeIsoGenerator(COUNTRY_CODES, TRAINING_SIZE, MAXLEN_X, MAXLEN_Y, INVERT)  \n",
    "    gen_dt_val   = DateTimeIsoGenerator(COUNTRY_CODES, VALIDATION_SIZE, MAXLEN_X, MAXLEN_Y, INVERT)\n",
    "    ## or\n",
    "    #gen_dt_train = DateTimeFormattedGenerator(COUNTRY_CODES, TRAINING_SIZE, MAXLEN_X, MAXLEN_Y, INVERT)\n",
    "    #gen_dt_val   = DateTimeFormattedGenerator(COUNTRY_CODES, VALIDATION_SIZE, MAXLEN_X, MAXLEN_Y, INVERT)\n",
    "\n",
    "    gen_vec_train      = DateTimeVectorGenerator(gen_dt_train, ctable)\n",
    "    gen_vec_validation = DateTimeVectorGenerator(gen_dt_val,   ctable)\n",
    "    \n",
    "    learning_hist.append(\n",
    "            model.fit_generator( gen_vec_train, \n",
    "                                samples_per_epoch=69993, \n",
    "                                nb_epoch=1, \n",
    "                                verbose=1, \n",
    "                                #callbacks=[], \n",
    "                                validation_data=gen_vec_validation, \n",
    "                                nb_val_samples=VALIDATION_SIZE, \n",
    "                                #class_weight={}, \n",
    "                                #max_q_size=10, \n",
    "                                #nb_worker=1, \n",
    "                                #pickle_safe=False\n",
    "                               )\n",
    "            )\n",
    "    ###\n",
    "    # Select 3 samples from the test set so we can visualize errors\n",
    "    if iteration % 5 == 0:         \n",
    "        model.save('./data/datatime_autoencoder_model.h5')\n",
    "        for i in range(3):\n",
    "            X_test, y_test = next(gen_vec_test)            \n",
    "            preds = model.predict_classes(X_test, verbose=0)\n",
    "            q = ctable.decode(X_test[0])\n",
    "            correct = ctable.decode(y_test[0])\n",
    "            guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "            print('Q', q[::-1] if INVERT else q )\n",
    "            print('T', correct)\n",
    "            print(colors.ok + '☑' + colors.close if correct == guess else colors.fail + '☒' + colors.close, guess)\n",
    "\n",
    "visualize_history(learning_hist)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Results</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h2>2 Layer, Relu, lr=0.01, 360(72*5) Hidden, ISO8601</h2>\n",
    "~~~\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2 Layer Adam, 333 Hidden, ISO8601</h2>\n",
    "~~~\n",
    "Iteration 20\n",
    "Epoch 1/1\n",
    "69993/69993 [==============================] - 41s - loss: 1.9638 - acc: 0.3964 - val_loss: 1.9701 - val_acc: 0.3957\n",
    "Q 2065-02-19 13:56:52                                                     \n",
    "T 2065-02-19T13:56:52       \n",
    "☒ 200000000000              \n",
    "Q 2065-02-19 13:56:52                                                     \n",
    "T 2065-02-19T13:56:52       \n",
    "☒ 200000000000              \n",
    "Q 2065-02-19 13:56:52                                                     \n",
    "T 2065-02-19T13:56:52       \n",
    "☒ 200000000000 \n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>3 Layer, Adam, 333 hidden, ISO8601</h2>\n",
    "~~~\n",
    "Iteration 200\n",
    "Epoch 1/1\n",
    "46662/46662 [==============================] - 32s - loss: 0.5656 - acc: 0.7843 - val_loss: 0.5589 - val_acc: 0.7904\n",
    "Q 2007-07-14T13:26:06                                                     \n",
    "T 2007-07-14T13:26:06       \n",
    "☒ 2007-07-11T11:57:57       \n",
    "Q 2007-07-14T13:26:06                                                     \n",
    "T 2007-07-14T13:26:06       \n",
    "☒ 2007-07-11T11:57:57       \n",
    "Q 2007-07-14T13:26:06                                                     \n",
    "T 2007-07-14T13:26:06       \n",
    "☒ 2007-07-11T11:57:57     \n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
